---
issue: content/issues/10-12-2021.md
category: News
keywords: []
date: 2021-12-07T12:54:42Z
article_title: 8 Days at ICA 4 First session in Paris
authors: []
picture: ''
picture_copyright: ''
yt: ''
published: false
pinned: false
bibliography: ''
redactors:
- firstname: 'Atrina '
  lastname: Oraee
  titles_and_institutions: []
  picture: ''
  picture_copyright: ''
  social_channels:
    website: ''
    wikipedia: ''
    orcid_id: ''
    linkedin: ''
    twitter: ''
    instagram: ''
    google_scholar: ''
    researchgate: ''
    mendeley: ''

---
The Intercontinental Academia (ICA) creates a global network of future research leaders in which some of the very best young academics work together on paradigm-shifting, cross-disciplinary research, mentored by eminent researchers from across the globe.

The ICA was established in 2016 through the University-Based Institutes for Advanced Study (UBIAS) coalition, which has 44 member institutes around the world.

During each edition of Intercontinental Academia, participants get together in three sessions over the course of one year.

Previous editions of ICA have focused on "Time", "Human Dignity" and "Laws: Rigidity and Dynamics".

The 4th edition of the ICA explores the complementarities between artificial intelligence and neuro/cognitive-science and the tremendous challenges and opportunities they raise for humanity. Fellows and mentors initially met online and in cyberspace, and now in presence in Paris, from October 18 to 27. They shall meet again in cyberspace in the next few months and then finally, in Belo Horizonte in Brazil next June.

The first session, hosted by Paris Institute for Advanced Study (Paris IAS), includes an intense 10-days of scientific sessions, discussion forums as well as scientific exchanges with ENS-Paris Saclay, Sorbonne Center for Artificial Intelligence and Ecole Normale Supérieure.

![](https://lh4.googleusercontent.com/Fu3P3brFSI8nb5ZQ15tR79S-uWB2TPo5drENasTMjJYf1cJrQCx7Yi34pCASrArkB84PveC-fGHng-_ySiqP1F7-0_WlrGnsEF0sfdRau1TxpOEIducIj98FrvEDAaWf3Q =602x448)

Each day at the[ Paris IAS](https://www.paris-iea.fr/en/ "Paris IEA"),[ ICA4 Fellows](https://www.intercontinental-academia.org/fellows "ICA4 Fellows") meet with their[ Mentors](https://www.intercontinental-academia.org/mentors "ICA4 Mentors") for a closed 3-hour seminar, during which two mentors launch the discussion with a presentation. Upon completion of the seminar, the Fellows then meet for 45 minutes to list the key takeaways and ideas that have emerged from the discussion, followed by a collective brainstorming session  . This ensures that the output of collective intelligence is collected, formatted and capitalised.

The other half of the day is left free for participants to reflect on the scientific discussions    in small groups. Such discussions are occasionally complemented by lectures from the[ **Chairs**](https://www.intercontinental-academia.org/about/ica4 "ICA4 Chairs").

1. **Day 1: "The future needs wisdom!”**

![](https://lh6.googleusercontent.com/yr6tstZ7PeffbJRW79vbbe03lxh7NfO5KtxbgkOY1DNKHYwyCFd4iGuYjhVU5s-ovCLSu99EovHca6DDH-dd9FxyeYfEmH4Z6hzvZThtrqwPSWLYqeWfLglR3tPSvkDzgQ =602x383)

The very first lecture of ICA4 - Session 1 came from[ _Robert Zatorre_](https://www.intercontinental-academia.org/mentors#zatorre "Robert Zatorre") who took us into the fascinating world of music while explaining the relationship between perception, predictions, and pleasure!

This was followed by another lecture that introduced a rather different perspective on AI and was presented by[ _Eliezer Rabinovici_](https://www.intercontinental-academia.org/about/ica4/#rabinovici "Eliezer Rabinovici")_._ The lecture mostly explored the complexities of scientific enquiries and methods in the context of AI.

Before leaving for cocktails and welcome speeches in the chambers of Paris IAS, a final lecture was given by[_Helga Nowotny_](http://helga-nowotny.eu "Helga Nowotny"), who emphasised an urgent need for establishing a context-sensitive AI control system.

* Perception, prediction, and pleasure: What can music teach us about neurocognition/intelligence?

  Presented by[ **_Robert Zatorre_**](https://www.intercontinental-academia.org/mentors#zatorre "Robert Zatorre")

  It was stated during the seminar that the brain represents the properties of the environment and guides behaviour through evaluation and reward. Aesthetic pleasure can be defined as the phylogenetically older system that is centred on the striatum.

  Moreover, results of the relation between connectivity of the auditory cortex with the striatum and several behavioural results were presented (e.g. related to amusia, music-specific anhedonia). Dynamic causal modelling and predictive coding frameworks have been presented as possible explanations of the relationship between learning and reward in music. Predictions make the rewards evolve from a biological event to the expectation of the event.

  Through the post-seminar collective discussions, the relevance of affective experience (pleasure and fear) in learning was emphasised. Discussions concluded with a rather open-ended question, leaving ICA4 Fellows wondering about whether or not AI should have a similar system for learning, and how should the reward and punishment be differentiated?" Maybe AI does not need to understand or experience human emotions; it just needs to behave like a human by capturing the features of a dataset that correctly describes the behaviour...
* High Energy Physics: Successes, Challenges and Magic

  Presented by[ **_Eliezer Rabinovici_**](https://www.intercontinental-academia.org/about/ica4/#rabinovici "Eliezer Rabinovici")

  It was discussed that observing natural phenomena can motivate scientific enquiry and drive us to understand the unknown. Moreover, equations are a way to increase predictability. However, a single, compact and reductionist explanation for all phenomena in the universe may not necessarily exist. The scientific method requires that results are reproducible. The correspondence principle requires that new theories can explain all phenomena for which a preceding theory was valid. To understand a phenomenon, one has to identify the relevant players and determine the correct explanation scale.
* In AI We Trust: Power, illusion and control of predictive algorithms

  Presented by[ **_Helga Nowotny_**](http://helga-nowotny.eu "Helga Nowotny")

  The session began with introducing the concept of singularity and defining it as a tipping point: a change of state that can lead to the collapse of a system. In an attempt to define Ethical AI, examples such as Transhumanism (ideas of transcending the limitations of a mortal body through information sharing) were discussed. Furthermore, the illusion that AI knows humans better than humans know themselves was elaborated, ultimately concluding by mentioning the existence of a possibility for human beings to both profit or suffer from an AI system depending on how it is applied.

  "The future needs wisdom”: an urgent need to institutionalise context-sensitivity, rather than creating a standardised system to control AI, was discussed and collectively developed. This lead to further debates regarding the concentration of technology advancement and its deteriorating impact on inequality. Thus, a global agreement is necessary to control AI, although it is currently almost impossible to obtain! Therefore, we should educate AI as a child of humanity that can grow to contribute to society. AI research is undertaken at such a massive scale that it requires global efforts which go beyond a single country. Scientists are paid by society, and their curiosity-led work should return to society as a whole…

   
  2. **Day 2: "In** **AI we** **trust"...or not!**

![](https://lh4.googleusercontent.com/0-dYD2PKA2ALZYDs2ZxilSutlxMpYOyGlXclyyWGqxIlU3dXW3jYTo8Pasd2fZSGrYT7s3icasKBxcZP882lZb_Zfdj82OJZpLNY3Pno7QyZDCtvJSBKvLurPC140KqW7Q =602x293)

The ICA4 continued onto the second day, through which three seminars took place with mentors who had joined the first session in Paris from around the world!

The first lecture was by[ _Robert Aumann_](https://www.intercontinental-academia.org/mentors#aumann "Robert Aumann"), a Nobel prize laureate, who focused on the convoluted concept of consciousness and its counterparts.

This was followed by a lecture from[ _Karen Yeung_](https://www.intercontinental-academia.org/mentors#yeung "Karen Yeung"), who offered a rather critical point of view on the prevalence of AI, as well as some of its surrounding myths and misconceptions. She then went on to explain how responsibility should be re-defined to consider the unintended impact(s) of AI in human societies.

Finally,[_Raouf Boucekkine _](https://www.intercontinental-academia.org/about/ica4#boucekkine "Raouf Boucekkine")took the fellows for an exploration into the world of economics and finance, using the concept of equilibrium as an example to illustrate the difference between disciplines: mainstream economics VS. statistical physics!

* Why Consciousness?

  Presented by[ **_Robert Aumann_**](https://www.intercontinental-academia.org/mentors#aumann)

  Essentially, the seminar was focused on the purpose which consciousness serves. Consciousness was defined as the ability to do the following:
  * Perceive
  * Feel (emotions)
  * Think/intend
  * Carry out intentions (volition)

  Of all the above, perceiving, thinking/intending, and carrying out intentions may be done by machines. However, feelings and emotions belong exclusively to human beings. In such a context, it may be argued that the evolutionary function of consciousness is to enable the operation of emotions. This being said, we currently have no idea about how does consciousness work. Although considerable progress has been made in AI, Artificial Emotions (AE) has remained rather untouched.


* Myths and misunderstandings about responsibility for the unintended impact of AI

  Presented by[ **_Karen Yeung_**](https://www.intercontinental-academia.org/mentors#yeung)

  The talk mostly focused on responsibility for the unintended impact of Artificial Intelligence, based on the presenter's Council of Europe study. It was argued that Machine Learning's (ML) capacity to enable task automation and machine "autonomy" raise important questions about responsibility. Thus, responsibility-relevant attributes of ML were identified, for which an illustration is the data-driven profiling of individuals, and other ML applications, which may hold adverse impacts on human rights, on both individual and collective levels.

  While responsibility is important for human beings, who are considered as moral agents, to maintain peaceful social co-operation within the community, only a few studies have focused on tackling the fundamental role of responsibility for individuals, as well as the society.

  The impacts produced by complex socio-technical systems using ML technologies have generated a range of concerns that fall under the heading of "algorithmic responsibility". While existing laws have an important role to play in ensuring the accountability of algorithmic systems, the implications of these technologies for their interference with human rights need to be studied further. This has been the primary focus of Karen Yeung's research.

  In a nutshell, two dimensions of responsibility are required:
  * Historic or retrospective responsibility: responsibility for conduct and events that occurred in the past
  * Prospective responsibility: roles and tasks that look to the future

  Finally, five common myths and misunderstandings concerning responsibility for the unintended adverse impacts of AI were identified:
  * Need for effective and legitimate mechanisms to protect human rights from AI applications.
  * Identifications of the appropriate responsibility model for allocating, distributing and preventing the various threats and risks.
  * Responsibility of states to ensure that these policy choices are made in a transparent and democratic manner, in order to effectively protect human rights.
  * Need for more interdisciplinary research
  * Application of the fundamental principle of reciprocity so as not to allow those who develop and run our advanced digital technologies and systems to increase and exercise their power without responsibility.


* Data science and deep learning vs theory: two examples from economics and finance

  Presented by[ **_Raouf Boucekkine_**](https://www.intercontinental-academia.org/about/ica4#boucekkine)

  The session included discussions on Data Science, Machine Learning (ML), and some relevant theories in the field of economics and finance that share common disciplines. Certain examples from macroeconomics, in which characteristics of the underlying mechanisms for complex systems are of great interest, were then discussed in more detail. In such context, a misunderstanding between different disciplines was highlighted: the concept of equilibrium is of great significance in mainstream macroeconomics, whereas this is not the case for statistical physics (e.g., the "equilibrium" bias outside the econ area, discussed by Bonneuil & Boucekkine (2020)). Finally, the use of various methods and approaches, such as DSGE (Dynamic Stochastic General Equilibrium), ABM (Agent-Based Modeling), and Neural Network-Based methods, in the field of macroeconomics were discussed.